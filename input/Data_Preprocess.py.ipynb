{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a7e76a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "104fd8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d6779f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 1 column 316 (char 315)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m json\u001b[38;5;241m.\u001b[39mloads(l)\n\u001b[1;32m----> 6\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparse_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./csvjson.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36mparse_data\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_data\u001b[39m(file):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m----> 4\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43ml\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\json\\decoder.py:340\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[1;32m--> 340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra data\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, end)\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Extra data: line 1 column 316 (char 315)"
     ]
    }
   ],
   "source": [
    "import json\n",
    "def parse_data(file):\n",
    "    for l in open(file,'r'):\n",
    "        yield json.loads(l)\n",
    "\n",
    "data = list(parse_data(\"./csvjson.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe5e55d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21114ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>It's said that #sarcasm is the lowest form of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I must weed out about 50 texts sounding like T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Callon is back, #sarcasm intact. Check out the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Personality so inspiring that every girl I mee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Why 50% valuation cut!? Nifty is just 8% down ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   created_at                                        description\n",
       "0           0  It's said that #sarcasm is the lowest form of ...\n",
       "1           1  I must weed out about 50 texts sounding like T...\n",
       "2           2  Callon is back, #sarcasm intact. Check out the...\n",
       "3           3  Personality so inspiring that every girl I mee...\n",
       "4           4  Why 50% valuation cut!? Nifty is just 8% down ..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['created_at','description']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6630d24d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>19.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.690452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>19.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>29.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>39.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       created_at\n",
       "count   40.000000\n",
       "mean    19.500000\n",
       "std     11.690452\n",
       "min      0.000000\n",
       "25%      9.750000\n",
       "50%     19.500000\n",
       "75%     29.250000\n",
       "max     39.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stats 1\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "932330ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    created_at                                        description\n",
      "0            0  It's said that #sarcasm is the lowest form of ...\n",
      "1            1  I must weed out about 50 texts sounding like T...\n",
      "2            2  Callon is back, #sarcasm intact. Check out the...\n",
      "3            3  Personality so inspiring that every girl I mee...\n",
      "4            4  Why 50% valuation cut!? Nifty is just 8% down ...\n",
      "5            5  BREAKUPS AND #SARCASM https://t.co/LGrjnIfWzQ ...\n",
      "6            6  @AyoCaesar Pretty sure this wasn't an endorsem...\n",
      "7            7  Answer  #nationwanttoknow #ANSWER #Mathematics...\n",
      "8            8   @IshitaJoshi @IamNaveenKapoor He did #Sarcasm ??\n",
      "9            9  Funny Quote - I'm Never Drinking Again https:/...\n",
      "10          10  Funny Retired Quote Mug  https://t.co/aAJq9xtx...\n",
      "11          11  Yay, Carey commentating. #Sarcasm #FkADuck #AF...\n",
      "12          12  Funny Sarcastic Quote - I Like My Puns Intende...\n",
      "13          13  Funny Quote - Literally Dead Tired https://t.c...\n",
      "14          14  Funny Coffee Quote - I Get Jealous https://t.c...\n",
      "15          15  Funny Coffee Quote - Sometimes I Go Hours With...\n",
      "16          16  Funny Quote - The Early Bird https://t.co/g3jk...\n",
      "17          17  Funny Coffee Quote - I'm A Great Multitasker h...\n",
      "18          18  Funny Coffee Quote - I'm Sorry for What I Said...\n",
      "19          19  Funny Coffee Mug Quote - I Don't Like Morning ...\n",
      "20          20  It's said that #sarcasm is the lowest form of ...\n",
      "21          21  THATS UNFORTUNATE https://t.co/Iln8ZioSqm #sar...\n",
      "22          22  #MarjorieTaylorGreene shes sensational #isn't ...\n",
      "23          23  Bahar dhoop dekh rahe ho kitni hai\" Is my new ...\n",
      "24          24  Every country has the right to chose its own m...\n",
      "25          25  I've just read that @metpoliceuk won't be inve...\n",
      "26          26  @MikeCarlton01 Forced service for minimum wage...\n",
      "27          27                    #sarcasm u dont get it? u dont?\n",
      "28          28  Rome is one of the first? Who would have ever ...\n",
      "29          29  You want to play a Roman legions #fantasy #ttr...\n",
      "30          30  @AshishGupta325 MBA bhi to kiya tha Nitie se i...\n",
      "31          31  @AllAboutThatBBQ @latimes I say that since we'...\n",
      "32          32  https://t.co/cCzIefCNw5 Top 5 Disgraced Celebr...\n",
      "33          33  @BaddyBird @PradyuPrasad For tone deaf people,...\n",
      "34          34  Back in my day, people used to take photos wit...\n",
      "35          35  @Virus_City_ What!? You mean Tesla hasn't prio...\n",
      "36          36  I fail to see Eiko's problem. It worked until ...\n",
      "37          37  my best college memory was not going to colleg...\n",
      "38          38  It's said that #sarcasm is the lowest form of ...\n",
      "39          39      @adhirasy @Ashvin1351 #Sarcasm at the best...\n"
     ]
    }
   ],
   "source": [
    "# dropping duplicate values\n",
    "df = df.drop_duplicates()\n",
    "print(df)\n",
    "\n",
    "##No Duplicates Found!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce1ac268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>19.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.690452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>19.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>29.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>39.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       created_at\n",
       "count   40.000000\n",
       "mean    19.500000\n",
       "std     11.690452\n",
       "min      0.000000\n",
       "25%      9.750000\n",
       "50%     19.500000\n",
       "75%     29.250000\n",
       "max     39.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stats 2\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a034326a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    created_at  description\n",
       "0        False        False\n",
       "1        False        False\n",
       "2        False        False\n",
       "3        False        False\n",
       "4        False        False\n",
       "5        False        False\n",
       "6        False        False\n",
       "7        False        False\n",
       "8        False        False\n",
       "9        False        False\n",
       "10       False        False\n",
       "11       False        False\n",
       "12       False        False\n",
       "13       False        False\n",
       "14       False        False\n",
       "15       False        False\n",
       "16       False        False\n",
       "17       False        False\n",
       "18       False        False\n",
       "19       False        False\n",
       "20       False        False\n",
       "21       False        False\n",
       "22       False        False\n",
       "23       False        False\n",
       "24       False        False\n",
       "25       False        False\n",
       "26       False        False\n",
       "27       False        False\n",
       "28       False        False\n",
       "29       False        False\n",
       "30       False        False\n",
       "31       False        False\n",
       "32       False        False\n",
       "33       False        False\n",
       "34       False        False\n",
       "35       False        False\n",
       "36       False        False\n",
       "37       False        False\n",
       "38       False        False\n",
       "39       False        False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for missing values\n",
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "673e72ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "created_at     0\n",
       "description    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the number of missing data\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b02e2114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0]\n",
      " [ 1]\n",
      " [ 2]\n",
      " [ 3]\n",
      " [ 4]\n",
      " [ 5]\n",
      " [ 6]\n",
      " [ 7]\n",
      " [ 8]\n",
      " [ 9]\n",
      " [10]\n",
      " [11]\n",
      " [12]\n",
      " [13]\n",
      " [14]\n",
      " [15]\n",
      " [16]\n",
      " [17]\n",
      " [18]\n",
      " [19]\n",
      " [20]\n",
      " [21]\n",
      " [22]\n",
      " [23]\n",
      " [24]\n",
      " [25]\n",
      " [26]\n",
      " [27]\n",
      " [28]\n",
      " [29]\n",
      " [30]\n",
      " [31]\n",
      " [32]\n",
      " [33]\n",
      " [34]\n",
      " [35]\n",
      " [36]\n",
      " [37]\n",
      " [38]\n",
      " [39]]\n"
     ]
    }
   ],
   "source": [
    "# Splitting dataset into independent & dependent variable\n",
    "X = df[['created_at']].values\n",
    "y = df['description'].values\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "026408aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"It's said that #sarcasm is the lowest form of #wit. To that I say, No, really? Hey, somebody give this person a #Nobel #peace #prize!\"\n",
      " 'I must weed out about 50 texts sounding like THIS per day. After 20 years, my responses are often sarcastic on steroids. Strangely, it relieves some of their annoyance. wHO ACTS LIKE THIS?  #humor #drudge #sarcasm 0#sessions https://t.co/hfjOLTAqKF'\n",
      " 'Callon is back, #sarcasm intact. Check out the #Allegiance sample on #bookbuzzr #mustread #fantasy #dragon - https://t.co/FI18RHQ5W8'\n",
      " 'Personality so inspiring that every girl I meet decides to focus on their career, rather than dating.#sarcasm #danj #ambition #saturday #memes'\n",
      " 'Why 50% valuation cut!? Nifty is just 8% down from ATH. Retail is strong enough to absorb FII selling.#Sarcasm https://t.co/1WIGugL6GX'\n",
      " 'BREAKUPS AND #SARCASM https://t.co/LGrjnIfWzQ #breakup #love https://t.co/qDRZwYTnPt'\n",
      " \"@AyoCaesar Pretty sure this wasn't an endorsement #sarcasm\"\n",
      " 'Answer  #nationwanttoknow #ANSWER #Mathematics #Quizzes #Memes #memecoin #Sarcasm #LOL #fun #educational https://t.co/tujXns0mRi'\n",
      " '@IshitaJoshi @IamNaveenKapoor He did #Sarcasm ??'\n",
      " \"Funny Quote - I'm Never Drinking Again https://t.co/muArTMYWYG via @zazzle #ZazzleMade #zazzle #Mugshots #mug #mugs #Coffee #CoffeeTime #sarcasm #sarcastic #quote #quoteoftheday #quotesdaily #sarcasticquotes #funnyquotes #giftideas #gift #gifts\"\n",
      " 'Funny Retired Quote Mug  https://t.co/aAJq9xtxia via @zazzle #ZazzleMade #zazzle #Mugshots #mug #mugs #Coffee #CoffeeTime #sarcasm #sarcastic #quote #quoteoftheday #quotesdaily #sarcasticquotes #funnyquotes #giftideas #gift #gifts #retirement'\n",
      " 'Yay, Carey commentating. #Sarcasm #FkADuck #AFLFreoBlues'\n",
      " 'Funny Sarcastic Quote - I Like My Puns Intended https://t.co/1czoroOg6s via @zazzle #ZazzleMade #zazzle #Mugshots #mug #mugs #Coffee #CoffeeTime #sarcasm #sarcastic #quote #quoteoftheday #quotesdaily #sarcasticquotes #funnyquotes #giftideas #gift #gifts'\n",
      " 'Funny Quote - Literally Dead Tired https://t.co/FG9Wq2O9MB via @zazzle #ZazzleMade #zazzle #Mugshots #mug #mugs #Coffee #CoffeeTime #sarcasm #sarcastic #quote #quoteoftheday #quotesdaily #sarcasticquotes #funnyquotes #giftideas #gift #gifts'\n",
      " 'Funny Coffee Quote - I Get Jealous https://t.co/LIBSH9YiUY via @zazzle #ZazzleMade #zazzle #Mugshots #mug #mugs #Coffee #CoffeeTime #sarcasm #sarcastic #quote #quoteoftheday #quotesdaily #sarcasticquotes #funnyquotes #giftideas #gift #gifts'\n",
      " 'Funny Coffee Quote - Sometimes I Go Hours Without https://t.co/6iUlDFCOS6 via @zazzle #ZazzleMade #zazzle #Mugshots #mug #mugs #Coffee #CoffeeTime #sarcasm #sarcastic #quote #quoteoftheday #quotesdaily #sarcasticquotes #funnyquotes #giftideas #gift #gifts'\n",
      " 'Funny Quote - The Early Bird https://t.co/g3jkH7nLhJ via @zazzle #ZazzleMade #zazzle #Mugshots #mug #mugs #Coffee #CoffeeTime #sarcasm #sarcastic #quote #quoteoftheday #quotesdaily #sarcasticquotes #funnyquotes #giftideas #gift #gifts'\n",
      " \"Funny Coffee Quote - I'm A Great Multitasker https://t.co/KfUoELgzmH via @zazzle #ZazzleMade #zazzle #Mugshots #mug #mugs #Coffee #CoffeeTime #sarcasm #sarcastic #quote #quoteoftheday #quotesdaily #sarcasticquotes #funnyquotes #giftideas #gift #gifts\"\n",
      " \"Funny Coffee Quote - I'm Sorry for What I Said https://t.co/fFEa6azqkQ via @zazzle #ZazzleMade #zazzle #Mugshots #mug #mugs #Coffee #CoffeeTime #sarcasm #sarcastic #quote #quoteoftheday #quotesdaily #sarcasticquotes #funnyquotes #giftideas #gift #gifts\"\n",
      " \"Funny Coffee Mug Quote - I Don't Like Morning Peoplehttps://t.co/gjuAEdKUjN via @zazzle #ZazzleMade #zazzle #Mugshots #mug #mugs #Coffee #CoffeeTime #sarcasm #sarcastic #quote #quoteoftheday #quotesdaily #sarcasticquotes #funnyquotes #giftideas #gift #gifts\"\n",
      " 'It\\'s said that #sarcasm is the lowest form of #wit. To that I say \"No, really? Hey, somebody give this person a #Nobel #peace #prize!'\n",
      " 'THATS UNFORTUNATE https://t.co/Iln8ZioSqm #sarcasm https://t.co/iAScBOMcMv'\n",
      " \"#MarjorieTaylorGreene shes sensational #isn't she? #sarcasm noted!! #PurjuryTaylorGreene https://t.co/VcaFmMA2NB\"\n",
      " 'Bahar dhoop dekh rahe ho kitni hai\" Is my new excuse to cancel every plan..!!#meme #memes #sarcasm #motivation #jokes #quote'\n",
      " 'Every country has the right to chose its own military alliance, but has to face the consequences. #Sarcasm https://t.co/JoslHOESAi'\n",
      " \"I've just read that @metpoliceuk won't be investigating Partygate until after the May elections.They've just confirmed that:They are corrupt and politically motivated.They hold British public for idiots.Well done #sarcasm\"\n",
      " '@MikeCarlton01 Forced service for minimum wage, that seems smart #Sarcasm'\n",
      " '#sarcasm u dont get it? u dont?'\n",
      " 'Rome is one of the first? Who would have ever thought?  #Sarcasm . https://t.co/kfvKExJGVB'\n",
      " \"You want to play a Roman legions #fantasy #ttrpg with supernatural elements?Among others: #LexArcana (and/or #CthulhuInvictus (#Coc) if you need the racist #Lovecraft...) #Sarcasm: It's really inspired to add some #Cthulhu / #Mythos garbage to everything! #CohorsCthulhu https://t.co/C02Vnkbsps https://t.co/BI25oKrMFj\"\n",
      " '@AshishGupta325 MBA bhi to kiya tha Nitie se in 2009-11. I think tab bhi struggle hogi to wake up at 9 AM So u were struggling even at age 25 also. I struggle today also to wake up early to go to office#Sarcasm'\n",
      " \"@AllAboutThatBBQ @latimes I say that since we're already like $3B in, we might as well just fight Russia ourselves and end it quicker. Considering Russia's anti-missile flagship got taken down by missiles, their nukes probably would never get off the ground. This is 50% #Sarcasm .\"\n",
      " 'https://t.co/cCzIefCNw5 Top 5 Disgraced Celebrities Of May 2022#top5 #celebs #top5list #disgraced #celebrities #marjorietaylorgreene #frankjames #kathrynkimballmizelle #judgemizelle #kathrynmizelle #chrisrock #joerogan #dontcensorme #sarcasm #sarcastic'\n",
      " '@BaddyBird @PradyuPrasad For tone deaf people, I need to post a sarcasm alert. #Sarcasm'\n",
      " 'Back in my day, people used to take photos with other people in them. https://t.co/fMTiNr7Fuq #sarcasm #tt #ttot #TBEX #LP #cleanhotels #travelmassive #travel'\n",
      " \"@Virus_City_ What!? You mean Tesla hasn't prioritized NN training for airplane avoidance? This is a safety hazard and I refuse to put our pilots lives in jeopardy. @tesla must be stopped! #sarcasm\"\n",
      " \"I fail to see Eiko's problem. It worked until it didn't. #sarcasm.Notice how in this moderate size trial with suicidal ideation as main outcome and participants at high-risk (most had a previous attempt) hard outcomes still look grim. https://t.co/gA8WHiDqS0 https://t.co/YRRdknpLNh\"\n",
      " 'my best college memory was not going to college#meme #memes #sarcasm #motivation #jokes #quote'\n",
      " 'It\\'s said that #sarcasm is the lowest form of #wit. To that I say \"No, really? Hey, somebody give this person a #Nobel #peace #prize!'\n",
      " '@adhirasy @Ashvin1351 #Sarcasm at the best...']\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6630c47d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     it's said that #sarcasm is the lowest form of ...\n",
       "1     i must weed out about 50 texts sounding like t...\n",
       "2     callon is back, #sarcasm intact. check out the...\n",
       "3     personality so inspiring that every girl i mee...\n",
       "4     why 50% valuation cut!? nifty is just 8% down ...\n",
       "5     breakups and #sarcasm https://t.co/lgrjnifwzq ...\n",
       "6     @ayocaesar pretty sure this wasn't an endorsem...\n",
       "7     answer  #nationwanttoknow #answer #mathematics...\n",
       "8      @ishitajoshi @iamnaveenkapoor he did #sarcasm ??\n",
       "9     funny quote - i'm never drinking again https:/...\n",
       "10    funny retired quote mug  https://t.co/aajq9xtx...\n",
       "11    yay, carey commentating. #sarcasm #fkaduck #af...\n",
       "12    funny sarcastic quote - i like my puns intende...\n",
       "13    funny quote - literally dead tired https://t.c...\n",
       "14    funny coffee quote - i get jealous https://t.c...\n",
       "15    funny coffee quote - sometimes i go hours with...\n",
       "16    funny quote - the early bird https://t.co/g3jk...\n",
       "17    funny coffee quote - i'm a great multitasker h...\n",
       "18    funny coffee quote - i'm sorry for what i said...\n",
       "19    funny coffee mug quote - i don't like morning ...\n",
       "20    it's said that #sarcasm is the lowest form of ...\n",
       "21    thats unfortunate https://t.co/iln8ziosqm #sar...\n",
       "22    #marjorietaylorgreene shes sensational #isn't ...\n",
       "23    bahar dhoop dekh rahe ho kitni hai\" is my new ...\n",
       "24    every country has the right to chose its own m...\n",
       "25    i've just read that @metpoliceuk won't be inve...\n",
       "26    @mikecarlton01 forced service for minimum wage...\n",
       "27                      #sarcasm u dont get it? u dont?\n",
       "28    rome is one of the first? who would have ever ...\n",
       "29    you want to play a roman legions #fantasy #ttr...\n",
       "30    @ashishgupta325 mba bhi to kiya tha nitie se i...\n",
       "31    @allaboutthatbbq @latimes i say that since we'...\n",
       "32    https://t.co/ccziefcnw5 top 5 disgraced celebr...\n",
       "33    @baddybird @pradyuprasad for tone deaf people,...\n",
       "34    back in my day, people used to take photos wit...\n",
       "35    @virus_city_ what!? you mean tesla hasn't prio...\n",
       "36    i fail to see eiko's problem. it worked until ...\n",
       "37    my best college memory was not going to colleg...\n",
       "38    it's said that #sarcasm is the lowest form of ...\n",
       "39        @adhirasy @ashvin1351 #sarcasm at the best...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lowercase\n",
    "\n",
    "df['description'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dfb0eae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                headline  is_sarcastic\n",
      "0      former versace store clerk sues over secret 'b...             0\n",
      "1      the 'roseanne' revival catches up to our thorn...             0\n",
      "2      mom starting to fear son's web series closest ...             1\n",
      "3      boehner just wants wife to listen, not come up...             1\n",
      "4      j.k. rowling wishes snape happy birthday in th...             0\n",
      "...                                                  ...           ...\n",
      "26704               american politics in moral free-fall             0\n",
      "26705                            america's best 20 hikes             0\n",
      "26706                              reparations and obama             0\n",
      "26707  israeli ban targeting boycott supporters raise...             0\n",
      "26708                  gourmet gifts for the foodie 2014             0\n",
      "\n",
      "[26602 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "815f5d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming \n",
    "df['description'] = df['description'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6b41a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tause\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "def preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    lemmas = [token.lemma_ for token in doc]\n",
    "    a_lemmas = [lemma.lower() for lemma in lemmas if lemma.isalpha() and lemma not in stopwords.words('english')]\n",
    "    lemmatized_text = ' '.join(a_lemmas)\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a15706ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = []\n",
    "for text in df.description:\n",
    "    cleaned_text.append(preprocess(text))\n",
    "df['clean_text'] = cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf436019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>description</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>it's said that #sarcasm is the lowest form of ...</td>\n",
       "      <td>say sarcasm low form wit i say really hey some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>i must weed out about 50 texts sounding like t...</td>\n",
       "      <td>i must weed text sound like per day year respo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>callon is back, #sarcasm intact. check out the...</td>\n",
       "      <td>callon back sarcasm intact check allegiance sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>personality so inspiring that every girl i mee...</td>\n",
       "      <td>personality inspiring every girl i meet decide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>why 50% valuation cut!? nifty is just 8% down ...</td>\n",
       "      <td>valuation cut nifty ath retail strong enough a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   created_at                                        description  \\\n",
       "0           0  it's said that #sarcasm is the lowest form of ...   \n",
       "1           1  i must weed out about 50 texts sounding like t...   \n",
       "2           2  callon is back, #sarcasm intact. check out the...   \n",
       "3           3  personality so inspiring that every girl i mee...   \n",
       "4           4  why 50% valuation cut!? nifty is just 8% down ...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  say sarcasm low form wit i say really hey some...  \n",
       "1  i must weed text sound like per day year respo...  \n",
       "2  callon back sarcasm intact check allegiance sa...  \n",
       "3  personality inspiring every girl i meet decide...  \n",
       "4  valuation cut nifty ath retail strong enough a...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12910b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.clean_text\n",
    "y = df.created_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a31552a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     say sarcasm low form wit i say really hey some...\n",
      "1     i must weed text sound like per day year respo...\n",
      "2     callon back sarcasm intact check allegiance sa...\n",
      "3     personality inspiring every girl i meet decide...\n",
      "4     valuation cut nifty ath retail strong enough a...\n",
      "5                          breakup sarcasm breakup love\n",
      "6                       pretty sure endorsement sarcasm\n",
      "7     answer nationwanttoknow answer mathematic quiz...\n",
      "8                                               sarcasm\n",
      "9     funny quote i never drink via zazzlemade zazzl...\n",
      "10    funny retire quote mug via zazzlemade zazzle m...\n",
      "11    yay carey commentating sarcasm fkaduck aflfreo...\n",
      "12    funny sarcastic quote i like pun intend via za...\n",
      "13    funny quote literally dead tired mb via zazzle...\n",
      "14    funny coffee quote i get jealous via zazzlemad...\n",
      "15    funny coffee quote sometimes i go hour without...\n",
      "16    funny quote early bird via zazzlemade zazzle m...\n",
      "17    funny coffee quote i great multitasker via zaz...\n",
      "18    funny coffee quote i sorry i say via zazzlemad...\n",
      "19    funny coffee mug quote i like morning via zazz...\n",
      "20    say sarcasm low form wit i say really hey some...\n",
      "21                                  unfortunate sarcasm\n",
      "22    marjorietaylorgreene sensational sarcasm note ...\n",
      "23    bahar dhoop dekh rahe ho kitni hai new excuse ...\n",
      "24    every country right chose military alliance fa...\n",
      "25    i read investigate partygate may confirm corru...\n",
      "26        force service minimum wage seem smart sarcasm\n",
      "27                                      sarcasm u get u\n",
      "28              rome one first would ever think sarcasm\n",
      "29    want play roman legion fantasy ttrpg supernatu...\n",
      "30    mba bhi kiya tha nitie se i think tab bhi stru...\n",
      "31    i say since already like might well fight russ...\n",
      "32    top disgrace celebrity may celebs disgrace cel...\n",
      "33    tone deaf people i need post sarcasm alert sar...\n",
      "34    back day people use take photo people sarcasm ...\n",
      "35    mean tesla prioritize nn training airplane avo...\n",
      "36    i fail see eiko problem work moderate size tri...\n",
      "37    good college memory go meme sarcasm motivation...\n",
      "38    say sarcasm low form wit i say really hey some...\n",
      "39                                         sarcasm good\n",
      "Name: clean_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cbf81712",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facc3362",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
